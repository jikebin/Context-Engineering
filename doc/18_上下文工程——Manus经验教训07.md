# 不要被“Few-Shot”所困

Agent的模仿者陷阱与“行为惯性”

## 从 “优点” 到 “副作用”

我们都知道Few-shot能教模型模仿范例，但Agent系统最大的问题恰恰在于，模型**太会模仿了**。

## 核心问题：行为惯性

如果上下文中充满了重复的Action-Observation对，它就会自动延续这种模式，**即使此时已并非最优**。

>例如：批量审核简历时，Agent可能因前几次都是“打开->总结->保存”，而陷入重复，不再综合分析。

## 问题本质：“自我Few-shot”陷阱

### Manus对深刻洞察

* 我们平时用Few-Shot是主动 “教” 模型；
* 但在 Agent 中，每一轮Action-Observation都在被动地产生新的“范例”。
* LLM不是在被我们Few-shot，而是在不断Few-shot它自己。

### 风险结果

* 随着任务循环，Agent的上下文历史越来越像一串训练样本。模型开始“沿着过去走”，而不是“规划未来”。
* 他不是在reasoning（推理），而是在repeating（重复）。

## 破局之道：引入“受控的多样性”

### Manus的解决方案

通过在重复的行为模式中，刻意的引入一些轻微的、结构化的**随机变化**，来打断模型的模仿节奏，迫使其重新评估上下文。

1. 不同的序列化模板：`Content saced...` -> `Successfully downloaded...`
2. 替代性措辞：`Open URL` -> `Fetch Website`
3. 格式上微小噪音：纯文本-> `{"status" : "success", ...}`

### 结论与升华

“模仿越稳定，智能越脆弱。”

一个真正的智能体，不是完美的复读机，而是会打断自己去重新思考。