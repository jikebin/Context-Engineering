# 高质量“摘要”的秘诀：告别自由格式，拥抱结构化Schema

## 问题的提出：摘要的“不可逆”风险

“摘要”是一个有损操作，如果提示词设计不当，就可能永久失去关键信息。如何确保摘要质量？

## 反直觉洞见：最好的摘要，是不让模型“写摘要”

* 错误做法：给模型开放式指令，如：“请总结...“，输出不稳定。
* 正确做法：定义一个结构化的”表单“ 或 ”模版“(Schema)，让AI去“填表”。
```md
原文示例字段：
- 我修改了哪些文件
- 用户的目标是什么
- 当前任务的进度如何
```

## 处理大型工具输出的两种策略

### 策略一：对于简单搜索

* 先完整返回，后依赖压缩
* 做法：将工具返回的全部、完整的详细结果直接追加到上下文中，以便模型能立刻、直接地利用这些信息。

**保险措施**：
同时指示模型，将中间洞见或关键发现主动用`write`工具写入文件，以防止因“压缩”过早发生而丢失信息。


### 策略二：对于复杂搜索

* 使用子Agent作为工具
* 做法：主Agent不直接调用底层工具，而是调用一个更高层次的函数(如`advanced_search`),该函数会触发一个独立的子Agent.这个子Agent在内部完成多次搜索、提炼后，只返回一个固定的、结构化的结果。

**最终效果**：
主Agent的上下文极其干净、高效，复杂性被完全封封装。

## 扩展：为何简单搜索不立即卸载？

### 为什么简单搜索不“立即卸载”？

既然”文件系统即上下文“是最安全的模式（工具返回后立即卸载，只保留指针），为何在处理简单搜索时，反而要先将完整内容返回上下文呢？

### 立即卸载的代价

需要”两次LLM调用“才能开始工作。

流程：`search->卸载->看指针->read_file->看内容->开始处理`。这个过程**延迟高、成本高**。

### 先返回原文的好处

只需要“一次LLM调用”就能开始工作。
流程：`search->看内容->立即开始处理`。这个过程**效率极高**。

### 最终的工程决策

对于那些Agent极有可能需要立即处理的工具结果（如果一次Google搜索），选择“先返回原文”来换取即时效率。而Peak提出的“保险措施”，正是为了对冲这种风险。